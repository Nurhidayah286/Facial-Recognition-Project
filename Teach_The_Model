# Install libraries, packages and dataset
import os
os.system('git clone https://github.com/parth1620/Facial-Expression-Dataset.git')
os.system('pip install -U git+https://github.com/albumentations-team/albumentations')
os.system('pip install timm')
os.system('pip install --upgrade opencv-contrib-python')

# Imports
import numpy as np
import matplotlib.pyplot as plt
import torch
import timm
import pandas as pd
from torch import nn
from torchvision.datasets import ImageFolder
from torchvision import transforms as T
from torch.utils.data import DataLoader
from tqdm import tqdm

# Configurations
TRAIN_IMG_FOLDER_PATH = './Facial-Expression-Dataset/train/'
VALID_IMG_FOLDER_PATH = './Facial-Expression-Dataset/validation/'

LR = 0.001
BATCH_SIZE = 32
EPOCHS = 15

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
MODEL_NAME = 'efficienet_b0'

# Load Dataset
trains_augs = T.Compose([
    T.RandomHorizontalFlip(p=0.5),
    T.RandomRotation(degrees=(-20, +20)),
    T.ToTensor()
])

valid_augs = T.Compose([
    T.ToTensor()
])

trainset = ImageFolder(TRAIN_IMG_FOLDER_PATH, transform=trains_augs)
validset = ImageFolder(VALID_IMG_FOLDER_PATH, transform=valid_augs)

print(f"Total no. of examples in trainset : {len(trainset)}")
print(f"Total no. of examples in validset : {len(validset)}")
print(trainset.class_to_idx)

# Load Dataset into Batches
trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)
validloader = DataLoader(validset, batch_size=BATCH_SIZE)

print(f"Total no. of batches in trainloader : {len(trainloader)}")
print(f"Total no. of batches in validloader : {len(validloader)}")

# Create Model
class FaceModel(nn.Module):
    def __init__(self):
        super(FaceModel, self).__init__()
        self.eff_net = timm.create_model('efficientnet_b0', pretrained=True, num_classes=7)

    def forward(self, images, labels=None):
        logits = self.eff_net(images)
        if labels is not None:
            loss = nn.CrossEntropyLoss()(logits, labels)
            return logits, loss
        return logits

model = FaceModel()
model.to(DEVICE)

# Create Train and Eval Function with Validation Results Collection
def multiclass_accuracy(y_pred, y_true):
    top_p, top_class = y_pred.topk(1, dim=1)
    equals = top_class == y_true.view(*top_class.shape)
    return torch.mean(equals.type(torch.FloatTensor))

def train_fn(model, dataloader, optimizer, current_epo):
    model.train()
    total_loss = 0.0
    total_acc = 0.0
    tk = tqdm(dataloader, desc=f"EPOCH[TRAIN]{current_epo + 1}/{EPOCHS}")

    for t, data in enumerate(tk):
        images, labels = data
        images, labels = images.to(DEVICE), labels.to(DEVICE)

        optimizer.zero_grad()
        logits, loss = model(images, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        total_acc += multiclass_accuracy(logits, labels)
        tk.set_postfix({'loss': '%6f' % float(total_loss/(t+1)), 'acc': '%6f' % float(total_acc/(t+1))})

    return total_loss/len(dataloader), total_acc/len(dataloader)

def eval_fn(model, dataloader, current_epo, save_results=False):
    model.eval()
    total_loss = 0.0
    total_acc = 0.0
    all_predictions = []
    all_true_labels = []
    all_probabilities = []

    tk = tqdm(dataloader, desc=f"EPOCH[VALID]{current_epo + 1}/{EPOCHS}")

    with torch.no_grad():
        for t, data in enumerate(tk):
            images, labels = data
            images, labels = images.to(DEVICE), labels.to(DEVICE)

            logits, loss = model(images, labels)
            probabilities = torch.softmax(logits, dim=1)

            total_loss += loss.item()
            total_acc += multiclass_accuracy(logits, labels)

            if save_results:
                _, predicted = torch.max(logits, 1)
                all_predictions.extend(predicted.cpu().numpy())
                all_true_labels.extend(labels.cpu().numpy())
                all_probabilities.extend(probabilities.cpu().numpy())

            tk.set_postfix({'loss': '%6f' % float(total_loss/(t+1)), 'acc': '%6f' % float(total_acc/(t+1))})

    if save_results:
        return total_loss/len(dataloader), total_acc/len(dataloader), all_predictions, all_true_labels, all_probabilities
    return total_loss/len(dataloader), total_acc/len(dataloader)

# Create Training Loop
def train_model():
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)
    best_valid_loss = np.Inf

    for i in range(EPOCHS):
        train_loss, train_acc = train_fn(model, trainloader, optimizer, i)
        valid_loss, valid_acc = eval_fn(model, validloader, i)

        if valid_loss < best_valid_loss:
            torch.save(model.state_dict(), 'best_weights.pt')
            print("SAVED-BEST-WEIGHTS")
            best_valid_loss = valid_loss

def save_validation_results():
    model.eval()
    # Now using the correct parameter name
    valid_loss, valid_acc, predictions, true_labels, probabilities = eval_fn(
        model, validloader, 0, save_results=True
    )

    classes = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']
    results = []

    for i in range(len(true_labels)):
        result = {
            'True_Label': classes[true_labels[i]],
            'Predicted_Label': classes[predictions[i]],
            'Correct': true_labels[i] == predictions[i],
        }

        # Add probabilities for each emotion
        for j, emotion in enumerate(classes):
            result[f'{emotion}_probability'] = probabilities[i][j]

        results.append(result)

    # Create DataFrames and save to Excel
    results_df = pd.DataFrame(results)

    # Create a summary DataFrame
    summary_data = {
        'Metric': ['Validation Loss', 'Validation Accuracy'],
        'Value': [valid_loss, valid_acc]
    }
    summary_df = pd.DataFrame(summary_data)

    # Save both DataFrames to different sheets in the same Excel file
    with pd.ExcelWriter('validation_results.xlsx') as writer:
        results_df.to_excel(writer, sheet_name='Detailed Results', index=False)
        summary_df.to_excel(writer, sheet_name='Summary', index=False)

        # Add confusion matrix
        confusion_matrix = pd.crosstab(
            pd.Series(results_df['True_Label'], name='Actual'),
            pd.Series(results_df['Predicted_Label'], name='Predicted')
        )
        confusion_matrix.to_excel(writer, sheet_name='Confusion Matrix')

    print("Validation results saved to 'validation_results.xlsx'")

# Inference visualization
def view_classify(img, ps):
    classes = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']

    ps = ps.data.cpu().numpy().squeeze()
    img = img.numpy().transpose(1,2,0)

    fig, (ax1, ax2) = plt.subplots(figsize=(5,9), ncols=2)
    ax1.imshow(img)
    ax1.axis('off')
    ax2.barh(classes, ps)
    ax2.set_aspect(0.1)
    ax2.set_yticks(range(len(classes)))
    ax2.set_yticklabels(classes)
    ax2.set_title('Class Probability')
    ax2.set_xlim(0, 1.1)

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    # Train the model
    train_model()

    # Load the best weights
    model.load_state_dict(torch.load('best_weights.pt'))

    # Save validation results
    save_validation_results()

    # Test an image
    image, label = validset[0]
    model.eval()
    with torch.no_grad():
        logits = model(image.unsqueeze(0).to(DEVICE))
        ps = torch.softmax(logits, dim=1)
    view_classify(image, ps)
